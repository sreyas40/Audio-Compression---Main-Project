{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "# Load the trained generator model\n",
    "generator = load_model('generator.h5')\n",
    "\n",
    "def preprocess_audio(file_path, sample_rate=22050, duration=5):\n",
    "    # Load the audio file\n",
    "    audio, file_sample_rate = sf.read(file_path)\n",
    "    \n",
    "    # Resample if needed\n",
    "    if file_sample_rate != sample_rate:\n",
    "        audio = librosa.resample(audio, orig_sr=file_sample_rate, target_sr=sample_rate)\n",
    "    \n",
    "    # Pad or truncate audio to fixed length\n",
    "    audio = pad_or_truncate(audio, int(sample_rate * duration))\n",
    "    \n",
    "    # Ensure audio is 2D: (length, 1) if mono, (length, channels) if stereo\n",
    "    if len(audio.shape) == 1:\n",
    "        audio = audio[:, np.newaxis]\n",
    "    \n",
    "    # Reshape to match the generator's expected input\n",
    "    audio = audio[np.newaxis, :, :].astype(np.float32)\n",
    "    \n",
    "    return audio\n",
    "\n",
    "def pad_or_truncate(audio, length):\n",
    "    if len(audio) > length:\n",
    "        return audio[:length]\n",
    "    elif len(audio) < length:\n",
    "        return np.pad(audio, (0, length - len(audio)), 'constant')\n",
    "    else:\n",
    "        return audio\n",
    "\n",
    "# Example: Preprocess your input .wav file\n",
    "input_file_path = \"test.wav\"\n",
    "preprocessed_audio = preprocess_audio(input_file_path)\n",
    "\n",
    "compressed_audio = generator.predict(preprocessed_audio)\n",
    "\n",
    "# Example: Save the compressed audio as a .flac file\n",
    "output_file_path = \"test-gen.flac\"\n",
    "\n",
    "# Reshape if needed (flattening to a single channel)\n",
    "compressed_audio = compressed_audio.squeeze()\n",
    "\n",
    "# Save using the soundfile library\n",
    "sf.write(output_file_path, compressed_audio, samplerate=22050)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
